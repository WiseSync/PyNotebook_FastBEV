{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intitalize All modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch\n",
    "import os\n",
    "\n",
    "model_root_path = 'model/tidl'\n",
    "\n",
    "DEVICE = 'cuda:0' if torch.cuda.is_available() else 'mps'\n",
    "    \n",
    "def preprocess_images(image_paths, input_size, mean, std):\n",
    "    images = []\n",
    "    for path in image_paths:\n",
    "        # 讀取並確保RGB\n",
    "        img = Image.open(path).convert('RGB')\n",
    "        new_img_width = input_size[1]\n",
    "        new_img_height = float(new_img_width) / img.size[0] * img.size[1]\n",
    "        \n",
    "        # Resize\n",
    "        img_resized = img.resize((int(new_img_width), int(new_img_height)), Image.LANCZOS)\n",
    "        crop_x = (img_resized.size[0] - input_size[1]) / 2\n",
    "        crop_y = (img_resized.size[1] - input_size[0]) / 2\n",
    "\n",
    "        crop_img = img_resized.crop((crop_x, crop_y, crop_x+input_size[1], crop_y+input_size[0]))\n",
    "        assert crop_img.size[0] == input_size[1] and crop_img.size[1] == input_size[0]\n",
    "\n",
    "        # 轉為Tensor(H,W,C)\n",
    "        img_tensor = torch.from_numpy(np.array(crop_img)).float().to(DEVICE)  # shape: (H, W, C)\n",
    "        \n",
    "        # 减均值，除標準差 (mean,std為C维度大小的tensor)\n",
    "        # 須先將Img tensor從 HWC -> CHW\n",
    "        img_tensor = img_tensor.permute(2,0,1)  # (C,H,W)\n",
    "        \n",
    "        # Broadcasting: (C,H,W) - (C,1,1) / (C,1,1)\n",
    "        # 將mean, std reshape成 (C,1,1)\n",
    "        mean = mean.view(-1,1,1)\n",
    "        std = std.view(-1,1,1)\n",
    "        \n",
    "        img_normalized = (img_tensor - mean) / std\n",
    "        \n",
    "        images.append(img_normalized)\n",
    "\n",
    "    # 將所有影像打包成 (N, C, H, W)\n",
    "    batch_images = torch.stack(images, dim=0)\n",
    "    return batch_images\n",
    "    \n",
    "batch_size = 6\n",
    "num_cameras = 6\n",
    "channels = 3\n",
    "height = 256\n",
    "width = 704\n",
    "\n",
    "\n",
    "output_features = np.zeros((batch_size, 64, 64, 176), dtype=np.float32)\n",
    "accu_time = 0\n",
    "\n",
    "def next_image_paths(imgid):\n",
    "    return [\n",
    "        f'data/samples/front/front_{imgid}.jpg',\n",
    "        f'data/samples/front_right/front_right_{imgid}.jpg',\n",
    "        f'data/samples/front_left/front_left_{imgid}.jpg',\n",
    "        f'data/samples/back/back_{imgid}.jpg',\n",
    "        f'data/samples/back_left/back_left_{imgid}.jpg',\n",
    "        f'data/samples/back_right/back_right_{imgid}.jpg',\n",
    "    ]\n",
    "\n",
    "# 假设您的模型期望输入尺寸为 256x704\n",
    "input_size = (256, 704)  # (height, width)\n",
    "\n",
    "# 使用与训练时相同的均值和标准差\n",
    "mean = torch.tensor([123.675, 116.28, 103.53], dtype=torch.float32).to(DEVICE)\n",
    "std = torch.tensor([58.395, 57.12, 57.375], dtype=torch.float32).to(DEVICE)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify the fastbev_pre_trt.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model = torch.load(os.path.join(model_root_path, \"fastbev_pre_trt.pth\"), weights_only=False).to(DEVICE)\n",
    "model.eval()\n",
    "# 用包裝過的模型執行PTQ\n",
    "#wrapper = WrapperModule(model)\n",
    "#onnx_model = onnx.load(os.path.join(model_root_path, \"fastbev_pre_trt.onnx\"))\n",
    "#model = convert(onnx_model).to(DEVICE)\n",
    "model_int8 = model\n",
    "\n",
    "num_samples = 1\n",
    "sample_output_features = np.zeros((num_samples, batch_size, 64, 64, 176), dtype=np.float32)\n",
    "\n",
    "#traced_model = symbolic_trace(model)\n",
    "\n",
    "#print(traced_model.graph)\n",
    "#model_int8 = traced_model\n",
    "\n",
    "output_features = np.zeros((batch_size, 64, 64, 176), dtype=np.float32)\n",
    "for imgid in range(1, 2):\n",
    "    img_paths = next_image_paths(imgid)\n",
    "    batch_images = preprocess_images(img_paths, input_size, mean, std)\n",
    "    for i in range(batch_size):\n",
    "        single_input_tensor = batch_images[i].unsqueeze(0).float()\n",
    "        #print(i, single_input_tensor.shape)\n",
    "        with torch.no_grad():\n",
    "            backbone_output = model_int8(single_input_tensor)\n",
    "            output_features[i] = backbone_output.cpu().numpy()    \n",
    "    sample_output_features[imgid-1] = output_features     \n",
    "\n",
    "num_images = output_features.shape[0]\n",
    "num_channels = 16  # 只显示前 16 个通道\n",
    "\n",
    "grid_rows = num_images\n",
    "grid_cols = num_channels\n",
    "for sample_idx in range(1):\n",
    "    plt.close()\n",
    "    fig, axes = plt.subplots(grid_rows, grid_cols, figsize=(grid_cols * 1.5, grid_rows * 1.5))\n",
    "    output_features = sample_output_features[sample_idx]\n",
    "    for img_idx in range(num_images):\n",
    "        for ch_idx in range(num_channels):\n",
    "            ax = axes[img_idx, ch_idx]\n",
    "            feature_map = output_features[img_idx, ch_idx, :, :]\n",
    "            ax.imshow(feature_map, cmap='viridis')\n",
    "            ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fastbev_pre_trt PTC training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import edgeai_torchmodelopt\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "model = torch.load(os.path.join(model_root_path, \"fastbev_pre_trt.pth\"), weights_only=False).to(DEVICE)\n",
    "model.eval()\n",
    "#onnx_model = onnx.load(os.path.join(model_root_path, \"fastbev_pre_trt.onnx\"))\n",
    "#model = convert(onnx_model).to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "\n",
    "model_int8 = edgeai_torchmodelopt.xmodelopt.quantization.v2.PTCFxModule(model, backend='qnnpack', bias_calibration_factor=0.01, num_batch_norm_update_epochs=1, num_observer_update_epochs=2)\n",
    "\n",
    "num_train_samples = 50\n",
    "num_epochs = 3\n",
    "\n",
    "for e in range(num_epochs):\n",
    "    print(f\"Epoch {e+1}/{num_epochs}\")\n",
    "    model_int8.train()\n",
    "    for s in tqdm(range(num_train_samples)):    \n",
    "        img_paths = next_image_paths(s+1)\n",
    "        batch_images = preprocess_images(img_paths, input_size, mean, std)\n",
    "        for i in range(batch_size):\n",
    "            single_input_tensor = batch_images[i].unsqueeze(0).float()\n",
    "            backbone_output = model_int8(single_input_tensor)\n",
    "\n",
    "\n",
    "model_int8.export(batch_images[0].reshape(1,channels, height, width) ,os.path.join(model_root_path, \"fastbev_pre_trt_int8.onnx\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the original and PTC models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# 假設 model_root_path, next_image_paths, preprocess_images, batch_size, channels, height, width, mean, std 都已定義\n",
    "# original_model_path: 未量化的 ONNX 模型路徑\n",
    "# quant_model_path: 量化後的 ONNX 模型路徑\n",
    "\n",
    "original_model_path = os.path.join(model_root_path, \"fastbev_pre_trt.onnx\")   # 未量化模型\n",
    "quant_model_path = os.path.join(model_root_path, \"fastbev_pre_trt_int8.onnx\") # 量化後模型\n",
    "\n",
    "# 建立ONNX推論session\n",
    "original_session = ort.InferenceSession(original_model_path, providers=['CPUExecutionProvider'])\n",
    "quant_session = ort.InferenceSession(quant_model_path, providers=['CPUExecutionProvider'])\n",
    "\n",
    "original_output_name = original_session.get_outputs()[0].name\n",
    "original_input_name = original_session.get_inputs()[0].name\n",
    "\n",
    "quant_output_name = quant_session.get_outputs()[0].name\n",
    "quant_input_name = quant_session.get_inputs()[0].name\n",
    "\n",
    "img_paths = next_image_paths(1)\n",
    "batch_images = preprocess_images(img_paths, input_size, mean, std) # shape: (N, C, H, W) torch tensor\n",
    "\n",
    "# 推論未量化模型\n",
    "original_output_features = np.zeros((batch_size, 64, 64, 176), dtype=np.float32)\n",
    "for i in range(batch_size):\n",
    "    start = time.time()\n",
    "    out = original_session.run(\n",
    "        [original_output_name],\n",
    "        {original_input_name: batch_images[i].cpu().numpy().reshape(1, channels, height, width)}\n",
    "    )[0]  # (1, 64, 64, 176)\n",
    "    original_output_features[i] = out[0]\n",
    "\n",
    "# 推論量化後模型\n",
    "quant_output_features = np.zeros((batch_size, 64, 64, 176), dtype=np.float32)\n",
    "for i in range(batch_size):\n",
    "    out = quant_session.run(\n",
    "        [quant_output_name],\n",
    "        {quant_input_name: batch_images[i].cpu().numpy().reshape(1, channels, height, width)}\n",
    "    )[0]\n",
    "    quant_output_features[i] = out[0]\n",
    "\n",
    "# 設定要顯示的通道數\n",
    "num_images = quant_output_features.shape[0]\n",
    "num_channels = 16 # 顯示前16個通道\n",
    "\n",
    "# 建立子圖: \n",
    "# 第一行: original model 特徵圖\n",
    "# 第二行: quant model 特徵圖\n",
    "# 第三行: 差異絕對值 (abs diff)\n",
    "grid_rows = 3 * num_images  # 每張影像佔3行\n",
    "grid_cols = num_channels\n",
    "\n",
    "fig, axes = plt.subplots(grid_rows, grid_cols, figsize=(grid_cols * 1.5, grid_rows * 1.5))\n",
    "for img_idx in range(num_images):\n",
    "    for ch_idx in range(num_channels):\n",
    "        orig_feat = original_output_features[img_idx, ch_idx, :, :]\n",
    "        quant_feat = quant_output_features[img_idx, ch_idx, :, :]\n",
    "        diff_feat = np.abs(orig_feat - quant_feat)\n",
    "        \n",
    "        # 原始特徵\n",
    "        ax_orig = axes[3*img_idx, ch_idx] # 第1行：original\n",
    "        ax_orig.imshow(orig_feat, cmap='viridis')\n",
    "        ax_orig.axis('off')\n",
    "        if ch_idx == 0:\n",
    "            ax_orig.set_ylabel(f\"Image {img_idx} \\nOriginal\", rotation=0, labelpad=50, va='center')\n",
    "        \n",
    "        # 量化後特徵\n",
    "        ax_quant = axes[3*img_idx+1, ch_idx] # 第2行：quantized\n",
    "        ax_quant.imshow(quant_feat, cmap='viridis')\n",
    "        ax_quant.axis('off')\n",
    "        if ch_idx == 0:\n",
    "            ax_quant.set_ylabel(\"Quantized\", rotation=0, labelpad=50, va='center')\n",
    "        \n",
    "        # 差異\n",
    "        ax_diff = axes[3*img_idx+2, ch_idx] # 第3行：diff\n",
    "        ax_diff.imshow(diff_feat, cmap='magma')\n",
    "        ax_diff.axis('off')\n",
    "        if ch_idx == 0:\n",
    "            ax_diff.set_ylabel(\"Diff\", rotation=0, labelpad=50, va='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify TIDL Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPDX-FileCopyrightText: Copyright (c) 2023 NVIDIA CORPORATION & AFFILIATES.\n",
    "# SPDX-License-Identifier: MIT\n",
    "\n",
    "import numpy as np\n",
    "import struct\n",
    "import os\n",
    "\n",
    "class DataType:\n",
    "    Float32 = 'Float32'\n",
    "    Float16 = 'Float16'\n",
    "    Int32 = 'Int32'\n",
    "    Int64 = 'Int64'\n",
    "    UInt64 = 'UInt64'\n",
    "    UInt32 = 'UInt32'\n",
    "    Int8 = 'Int8'\n",
    "    UInt8 = 'UInt8'\n",
    "    Int16 = 'Int16'\n",
    "    UInt16 = 'UInt16'\n",
    "    NoneType = 'None'\n",
    "\n",
    "def dtype_string(dtype):\n",
    "    return dtype\n",
    "\n",
    "def dtype_bytes(dtype):\n",
    "    dtype_map = {\n",
    "        DataType.Float32: 4,\n",
    "        DataType.Float16: 2,\n",
    "        DataType.Int32: 4,\n",
    "        DataType.Int64: 8,\n",
    "        DataType.UInt64: 8,\n",
    "        DataType.UInt32: 4,\n",
    "        DataType.Int8: 1,\n",
    "        DataType.UInt8: 1,\n",
    "        DataType.Int16: 2,\n",
    "        DataType.UInt16: 2,\n",
    "    }\n",
    "    return dtype_map.get(dtype, 0)\n",
    "\n",
    "def format_shape(shape):\n",
    "    return ' x '.join(map(str, shape))\n",
    "\n",
    "class TensorData:\n",
    "    def __init__(self, data=None, dtype=DataType.NoneType, device=False):\n",
    "        self.data = data\n",
    "        self.dtype = dtype\n",
    "        self.device = device  # In this Python version, we will ignore device handling\n",
    "        self.owner = True if data is not None else False\n",
    "\n",
    "    @staticmethod\n",
    "    def create(size, dtype):\n",
    "        dtype_np = TensorData.dtype_to_numpy(dtype)\n",
    "        data = np.zeros(size, dtype=dtype_np)\n",
    "        return TensorData(data, dtype)\n",
    "\n",
    "    @staticmethod\n",
    "    def dtype_to_numpy(dtype):\n",
    "        dtype_map = {\n",
    "            DataType.Float32: np.float32,\n",
    "            DataType.Float16: np.float16,\n",
    "            DataType.Int32: np.int32,\n",
    "            DataType.Int64: np.int64,\n",
    "            DataType.UInt64: np.uint64,\n",
    "            DataType.UInt32: np.uint32,\n",
    "            DataType.Int8: np.int8,\n",
    "            DataType.UInt8: np.uint8,\n",
    "            DataType.Int16: np.int16,\n",
    "            DataType.UInt16: np.uint16,\n",
    "        }\n",
    "        return dtype_map.get(dtype, np.float32)\n",
    "\n",
    "class Tensor:\n",
    "    def __init__(self, shape=None, dtype=DataType.Float32, device=False):\n",
    "        self.shape = shape if shape is not None else []\n",
    "        self.dtype = dtype\n",
    "        self.device = device  # Device handling is omitted in this Python version\n",
    "        self.data = None\n",
    "        self.numel = np.prod(self.shape) if self.shape else 0\n",
    "        self.ndim = len(self.shape)\n",
    "        if self.numel > 0:\n",
    "            self.data = TensorData.create(self.numel, self.dtype)\n",
    "\n",
    "    @staticmethod\n",
    "    def create(shape, dtype=DataType.Float32, device=False):\n",
    "        return Tensor(shape, dtype, device)\n",
    "\n",
    "    def empty(self):\n",
    "        return self.data is None or self.numel == 0\n",
    "\n",
    "    def ptr(self):\n",
    "        return self.data.data if self.data else None\n",
    "\n",
    "    def load(self, file_path):\n",
    "        if not os.path.isfile(file_path):\n",
    "            print(f\"File {file_path} does not exist.\")\n",
    "            return None\n",
    "\n",
    "        with open(file_path, 'rb') as f:\n",
    "            head = f.read(12)\n",
    "            if len(head) < 12:\n",
    "                print(f\"This is invalid tensor file {file_path}\")\n",
    "                return None\n",
    "\n",
    "            magic_number, ndim, dtypei = struct.unpack('3i', head)\n",
    "            if magic_number != 0x33FF1101:\n",
    "                print(f\"This is invalid tensor file {file_path}\")\n",
    "                return None\n",
    "\n",
    "            dims = struct.unpack(f'{ndim}i', f.read(4 * ndim))\n",
    "            shape = list(dims)\n",
    "            volumn = np.prod(shape)\n",
    "            dtype = self.int_to_dtype(dtypei)\n",
    "            bytes_needed = volumn * dtype_bytes(dtype)\n",
    "\n",
    "            data = f.read(bytes_needed)\n",
    "            if len(data) < bytes_needed:\n",
    "                print(f\"This is invalid tensor file {file_path}\")\n",
    "                return None\n",
    "\n",
    "            #dtype_np = np.dtype(TensorData.dtype_to_numpy(dtype))# \n",
    "            dtype_np = TensorData.dtype_to_numpy(dtype)# \n",
    "            #dtype_np = dtype_np.newbyteorder('>')\n",
    "            tensor_data = np.frombuffer(data, dtype=dtype_np).reshape(shape)\n",
    "\n",
    "            self.shape = shape\n",
    "            self.dtype = dtype\n",
    "            self.numel = volumn\n",
    "            self.ndim = ndim\n",
    "            self.data = TensorData(tensor_data, dtype)\n",
    "            return self\n",
    "\n",
    "    def save(self, file_path):\n",
    "        if self.empty():\n",
    "            print(\"Tensor is empty. Nothing to save.\")\n",
    "            return False\n",
    "\n",
    "        with open(file_path, 'wb') as f:\n",
    "            magic_number = 0x33FF1101\n",
    "            ndim = self.ndim\n",
    "            dtypei = self.dtype_to_int(self.dtype)\n",
    "            head = struct.pack('3i', magic_number, ndim, dtypei)\n",
    "            f.write(head)\n",
    "            dims = struct.pack(f'{ndim}i', *self.shape)\n",
    "            f.write(dims)\n",
    "            f.write(self.data.data.tobytes())\n",
    "        return True\n",
    "\n",
    "    @staticmethod\n",
    "    def dtype_to_int(dtype):\n",
    "        dtype_map = {\n",
    "            DataType.NoneType: 0,\n",
    "            DataType.Int32: 1,\n",
    "            DataType.Float16: 2,\n",
    "            DataType.Float32: 3,\n",
    "            DataType.Int64: 4,\n",
    "            DataType.UInt64: 5,\n",
    "            DataType.UInt32: 6,\n",
    "            DataType.Int8: 7,\n",
    "            DataType.UInt8: 8,\n",
    "            DataType.UInt16: 9,\n",
    "            DataType.Int16: 10,\n",
    "        }\n",
    "        return dtype_map.get(dtype, -1)\n",
    "\n",
    "    @staticmethod\n",
    "    def int_to_dtype(dtypei):\n",
    "        dtype_map = {\n",
    "            0: DataType.NoneType,\n",
    "            1: DataType.Int32,\n",
    "            2: DataType.Float16,\n",
    "            3: DataType.Float32,\n",
    "            4: DataType.Int64,\n",
    "            5: DataType.UInt64,\n",
    "            6: DataType.UInt32,\n",
    "            7: DataType.Int8,\n",
    "            8: DataType.UInt8,\n",
    "            9: DataType.UInt16,\n",
    "            10: DataType.Int16,\n",
    "        }\n",
    "        return dtype_map.get(dtypei, DataType.NoneType)\n",
    "\n",
    "    def print(self, prefix='', offset=0, num_per_line=10, lines=1):\n",
    "        print(f\"{prefix}[{dtype_string(self.dtype)}] {format_shape(self.shape)}:\", end='\\n' if lines > 1 else ' ')\n",
    "        if self.empty():\n",
    "            print(\"empty.\")\n",
    "            return\n",
    "\n",
    "        num_print = min(lines * num_per_line, self.numel)\n",
    "        data_to_print = self.data.data.flatten()[offset:offset+num_print]\n",
    "        for idx, value in enumerate(data_to_print):\n",
    "            print(value, end=' ')\n",
    "            if (idx + 1) % num_per_line == 0:\n",
    "                print()\n",
    "        if num_print % num_per_line != 0:\n",
    "            print()\n",
    "\n",
    "    def arange(self):\n",
    "        if self.empty():\n",
    "            return\n",
    "        self.data.data = np.arange(self.numel, dtype=TensorData.dtype_to_numpy(self.dtype)).reshape(self.shape)\n",
    "\n",
    "    def clone(self):\n",
    "        if self.empty():\n",
    "            return Tensor()\n",
    "        cloned_tensor = Tensor(self.shape, self.dtype, self.device)\n",
    "        cloned_tensor.data.data = np.copy(self.data.data)\n",
    "        return cloned_tensor\n",
    "\n",
    "    def to_float(self):\n",
    "        if self.empty():\n",
    "            return Tensor()\n",
    "        if self.dtype == DataType.Float32:\n",
    "            return self.clone()\n",
    "        converted_tensor = Tensor(self.shape, DataType.Float32, self.device)\n",
    "        converted_tensor.data.data = self.data.data.astype(np.float32)\n",
    "        return converted_tensor\n",
    "\n",
    "    def to_half(self):\n",
    "        if self.empty():\n",
    "            return Tensor()\n",
    "        if self.dtype == DataType.Float16:\n",
    "            return self.clone()\n",
    "        converted_tensor = Tensor(self.shape, DataType.Float16, self.device)\n",
    "        converted_tensor.data.data = self.data.data.astype(np.float16)\n",
    "        return converted_tensor\n",
    "    \n",
    "    def np(self):\n",
    "        if self.empty():\n",
    "            return None\n",
    "        return self.data.data\n",
    "\n",
    "    def memset(self, value):\n",
    "        if self.empty():\n",
    "            return\n",
    "        self.data.data.fill(value)\n",
    "\n",
    "# 假设您已经将 valid_c_idx, x, y 数据保存为 .npy 文件\n",
    "valid_c_idx = Tensor()\n",
    "valid_c_idx = valid_c_idx.load(file_path='data/valid_c_idx.tensor')\n",
    "valid_x = Tensor()\n",
    "valid_x = valid_x.load(file_path='data/x.tensor')\n",
    "valid_y = Tensor()\n",
    "valid_y = valid_y.load(file_path='data/y.tensor')\n",
    "\n",
    "\n",
    "\n",
    "def view_transform(camera_features, valid_c_idx, valid_x, valid_y):\n",
    "    # camera_features: (num_cameras, channels, height, width)\n",
    "    channels = camera_features.shape[1]\n",
    "    volume_x = 200\n",
    "    volume_y = 200\n",
    "    volume_z = 4\n",
    "\n",
    "    volume_shape = (channels, volume_x, volume_y, volume_z)\n",
    "    num_cameras, channels, height, width = camera_features.shape\n",
    "    num_valid = valid_c_idx.shape[1] \n",
    "    \n",
    "    # 初始化输出 BEV 特征\n",
    "    bev_features = np.zeros((channels*num_valid), dtype=np.float32)\n",
    "    \n",
    "    # 创建一个 mask，表示哪些点是有效的\n",
    "    valid_mask = valid_c_idx == 1.0  # 形状为 (num_cameras, num_valid)\n",
    "    \n",
    "    for c in range(num_cameras):\n",
    "        for i in range(num_valid):\n",
    "            if valid_c_idx[c, i] == 0.0:\n",
    "                continue\n",
    "            x = valid_x[c, i]\n",
    "            y = valid_y[c, i]\n",
    "            \"\"\" for(int c=0; c< 64; c++){\n",
    "                output_feature[c*num_valid+tid] = camera_feature[icamera*64*feat_height*feat_width+c*feat_height*feat_width +feat_width*y+x];\n",
    "            } \"\"\"\n",
    "            for ch in range(channels):\n",
    "                index = ch*num_valid+i\n",
    "                i#f(index==0 or index==1000 or index==5000 or index==32758):\n",
    "                    #print(x, y, c, camera_features[c, ch, y, x])\n",
    "                bev_features[index] = camera_features[c, ch, y, x]\n",
    "    #SLOG_INFO<<output_feature[0]<<\", \"<<output_feature[1000]<<\", \"<<output_feature[5000]<<\", \"<<output_feature[32758]<<std::endl;\n",
    "    #print(bev_features[0], bev_features[1000], bev_features[5000], bev_features[32758])\n",
    "    bev_features = bev_features.reshape(volume_shape)\n",
    "\n",
    "    return bev_features\n",
    "\n",
    "# 将 backbone_output 调整形状以匹配函数输入\n",
    "# 假设 backbone_output 形状为 (1, num_cameras * channels, height, width)\n",
    "num_cameras =  sample_output_features.shape[1]\n",
    "channels =  sample_output_features.shape[2]\n",
    "height =  sample_output_features.shape[3]\n",
    "width =  sample_output_features.shape[4]\n",
    "\n",
    "#print(valid_x.np().shape)\n",
    "sample_bev_features = np.zeros((num_samples, 1, 64, 200, 200, 4), dtype=np.float32)\n",
    "for sample_idx in range(num_samples):\n",
    "    bev_features = view_transform(sample_output_features[sample_idx], valid_c_idx.np(), valid_x.np(), valid_y.np())\n",
    "    bev_features = bev_features[np.newaxis, :, :]  # 形状为 (1, channels, volume_x, volume_y, volume_z)\n",
    "    sample_bev_features[sample_idx] = bev_features\n",
    "    # 显示 BEV 特征\n",
    "    num_images = bev_features.shape[4]\n",
    "    num_channels = 16  # 只显示前 16 个通道\n",
    "\n",
    "    grid_rows = num_images\n",
    "    grid_cols = num_channels\n",
    "\n",
    "    plt.close()\n",
    "    fig, axes = plt.subplots(grid_rows, grid_cols, figsize=(grid_cols * 1.5, grid_rows * 1.5))\n",
    "    for img_idx in range(num_images):\n",
    "        for ch_idx in range(num_channels):\n",
    "            ax = axes[img_idx, ch_idx]\n",
    "            feature_map = bev_features[0][ch_idx, :, :,img_idx]\n",
    "            ax.imshow(feature_map, cmap='viridis')\n",
    "            ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'data/bev_features/bev_features_{sample_idx}.png')\n",
    "    #plt.tight_layout()\n",
    "    #plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "    \n",
    "def cross(p1, p2, p0):\n",
    "    # 计算向量 (p1 - p0) 和 (p2 - p0) 的叉积\n",
    "    return (p1[0] - p0[0]) * (p2[1] - p0[1]) - (p2[0] - p0[0]) * (p1[1] - p0[1])\n",
    "    \n",
    "def check_box2d(box, p):\n",
    "    # 检查点 p 是否在旋转矩形 box 内部\n",
    "    MARGIN = 1e-5\n",
    "    center_x = (box[0] + box[2]) / 2\n",
    "    center_y = (box[1] + box[3]) / 2\n",
    "    angle_cos = np.cos(-box[4])\n",
    "    angle_sin = np.sin(-box[4])\n",
    "    rot_x = (p[0] - center_x) * angle_cos + (p[1] - center_y) * angle_sin + center_x\n",
    "    rot_y = -(p[0] - center_x) * angle_sin + (p[1] - center_y) * angle_cos + center_y\n",
    "    return (rot_x > (box[0] - MARGIN) and rot_x < (box[2] + MARGIN) and\n",
    "            rot_y > (box[1] - MARGIN) and rot_y < (box[3] + MARGIN))\n",
    "\n",
    "def intersection(p1, p0, q1, q0):\n",
    "    # 计算两条线段 (p0, p1) 和 (q0, q1) 的交点\n",
    "    # 返回 (交点存在标志, 交点坐标)\n",
    "    ThresHold = 1e-8\n",
    "    if not (min(p0[0], p1[0]) <= max(q0[0], q1[0]) and\n",
    "            min(q0[0], q1[0]) <= max(p0[0], p1[0]) and\n",
    "            min(p0[1], p1[1]) <= max(q0[1], q1[1]) and\n",
    "            min(q0[1], q1[1]) <= max(p0[1], p1[1])):\n",
    "        return False, None\n",
    "\n",
    "    s1 = cross(q0, p1, p0)\n",
    "    s2 = cross(p1, q1, p0)\n",
    "    s3 = cross(p0, q1, q0)\n",
    "    s4 = cross(q1, p1, q0)\n",
    "\n",
    "    if not (s1 * s2 > 0 and s3 * s4 > 0):\n",
    "        return False, None\n",
    "\n",
    "    s5 = cross(q1, p1, p0)\n",
    "    if abs(s5 - s1) > ThresHold:\n",
    "        ans_x = (s5 * q0[0] - s1 * q1[0]) / (s5 - s1)\n",
    "        ans_y = (s5 * q0[1] - s1 * q1[1]) / (s5 - s1)\n",
    "    else:\n",
    "        a0 = p0[1] - p1[1]\n",
    "        b0 = p1[0] - p0[0]\n",
    "        c0 = p0[0] * p1[1] - p1[0] * p0[1]\n",
    "        a1 = q0[1] - q1[1]\n",
    "        b1 = q1[0] - q0[0]\n",
    "        c1 = q0[0] * q1[1] - q1[0] * q0[1]\n",
    "        D = a0 * b1 - a1 * b0\n",
    "        ans_x = (b0 * c1 - b1 * c0) / D\n",
    "        ans_y = (a1 * c0 - a0 * c1) / D\n",
    "\n",
    "    return True, (ans_x, ans_y)\n",
    "\n",
    "def rotate_around_center(center, angle_cos, angle_sin, p):\n",
    "    # 绕中心点旋转点 p\n",
    "    new_x = (p[0] - center[0]) * angle_cos + (p[1] - center[1]) * angle_sin + center[0]\n",
    "    new_y = -(p[0] - center[0]) * angle_sin + (p[1] - center[1]) * angle_cos + center[1]\n",
    "    return [new_x, new_y]\n",
    "\n",
    "def box_overlap(box_a, box_b):\n",
    "    # 计算两个旋转矩形的重叠面积\n",
    "    ThresHold = 1e-8\n",
    "    a_angle = box_a[4]\n",
    "    b_angle = box_b[4]\n",
    "    a_x1, a_y1, a_x2, a_y2 = box_a[0], box_a[1], box_a[2], box_a[3]\n",
    "    b_x1, b_y1, b_x2, b_y2 = box_b[0], box_b[1], box_b[2], box_b[3]\n",
    "    box_a_corners = []\n",
    "    box_b_corners = []\n",
    "    cross_points = []\n",
    "    poly_center = [0, 0]\n",
    "    cnt = 0\n",
    "\n",
    "    center_a = [(a_x1 + a_x2) / 2, (a_y1 + a_y2) / 2]\n",
    "    center_b = [(b_x1 + b_x2) / 2, (b_y1 + b_y2) / 2]\n",
    "\n",
    "    box_a_corners = [\n",
    "        [a_x1, a_y1],\n",
    "        [a_x2, a_y1],\n",
    "        [a_x2, a_y2],\n",
    "        [a_x1, a_y2],\n",
    "    ]\n",
    "\n",
    "    box_b_corners = [\n",
    "        [b_x1, b_y1],\n",
    "        [b_x2, b_y1],\n",
    "        [b_x2, b_y2],\n",
    "        [b_x1, b_y2],\n",
    "    ]\n",
    "\n",
    "    a_angle_cos = np.cos(a_angle)\n",
    "    a_angle_sin = np.sin(a_angle)\n",
    "    b_angle_cos = np.cos(b_angle)\n",
    "    b_angle_sin = np.sin(b_angle)\n",
    "\n",
    "    for k in range(4):\n",
    "        box_a_corners[k] = rotate_around_center(center_a, a_angle_cos, a_angle_sin, box_a_corners[k])\n",
    "        box_b_corners[k] = rotate_around_center(center_b, b_angle_cos, b_angle_sin, box_b_corners[k])\n",
    "\n",
    "    box_a_corners.append(box_a_corners[0])  # 闭合多边形\n",
    "    box_b_corners.append(box_b_corners[0])\n",
    "\n",
    "    # 寻找交点\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            flag, ans = intersection(box_a_corners[i + 1], box_a_corners[i], box_b_corners[j + 1], box_b_corners[j])\n",
    "            if flag:\n",
    "                poly_center[0] += ans[0]\n",
    "                poly_center[1] += ans[1]\n",
    "                cross_points.append(ans)\n",
    "                cnt += 1\n",
    "\n",
    "    # 检查是否有顶点在对方的矩形内部\n",
    "    for k in range(4):\n",
    "        if check_box2d(box_a, box_b_corners[k]):\n",
    "            poly_center[0] += box_b_corners[k][0]\n",
    "            poly_center[1] += box_b_corners[k][1]\n",
    "            cross_points.append(box_b_corners[k])\n",
    "            cnt += 1\n",
    "        if check_box2d(box_b, box_a_corners[k]):\n",
    "            poly_center[0] += box_a_corners[k][0]\n",
    "            poly_center[1] += box_a_corners[k][1]\n",
    "            cross_points.append(box_a_corners[k])\n",
    "            cnt += 1\n",
    "\n",
    "    if cnt == 0:\n",
    "        return 0.0\n",
    "\n",
    "    poly_center[0] /= cnt\n",
    "    poly_center[1] /= cnt\n",
    "\n",
    "    # 根据极角排序\n",
    "    def angle_cmp(p):\n",
    "        return np.arctan2(p[1] - poly_center[1], p[0] - poly_center[0])\n",
    "\n",
    "    cross_points.sort(key=angle_cmp)\n",
    "\n",
    "    # 计算多边形面积\n",
    "    area = 0.0\n",
    "    for k in range(len(cross_points)):\n",
    "        x1, y1 = cross_points[k]\n",
    "        x2, y2 = cross_points[(k + 1) % len(cross_points)]\n",
    "        area += (x1 * y2 - x2 * y1)\n",
    "    area = abs(area) / 2.0\n",
    "    return area\n",
    "\n",
    "def nms_cpu(boxes, scores, nms_thresh):\n",
    "    # boxes: List of boxes, each box is [x1, y1, x2, y2, angle]\n",
    "    # scores: List of scores\n",
    "    # nms_thresh: IOU threshold for NMS\n",
    "    order = np.argsort(-np.array(scores))\n",
    "    keep = np.zeros(len(boxes), dtype=bool)\n",
    "    selected_indices = []\n",
    "\n",
    "    for idx_i in range(len(order)):\n",
    "        i = order[idx_i]\n",
    "        if keep[idx_i] or idx_i >= len(order)-1:\n",
    "            continue\n",
    "        for idx_j in range(idx_i + 1, len(order)):\n",
    "            j = order[idx_j]\n",
    "            if keep[idx_j]:\n",
    "                continue\n",
    "            sa = (boxes[i][2] - boxes[i][0]) * (boxes[i][3] - boxes[i][1])\n",
    "            sb = (boxes[j][2] - boxes[j][0]) * (boxes[j][3] - boxes[j][1])\n",
    "            s_overlap = box_overlap(boxes[i], boxes[j])\n",
    "            iou = s_overlap / max(sa + sb - s_overlap, 1e-8)\n",
    "            if iou >= nms_thresh:\n",
    "                keep[idx_j] = True\n",
    "\n",
    "    for idx in range(len(keep)):\n",
    "        if not keep[idx]:\n",
    "            selected_indices.append(order[idx])\n",
    "    return selected_indices\n",
    "\n",
    "def decode(anchors, deltas):\n",
    "    \"\"\"Apply transformation `deltas` (dx, dy, dz, dw, dh, dl, dr, dv*) to\n",
    "    `boxes`.\n",
    "\n",
    "    Args:\n",
    "        anchors (torch.Tensor): Parameters of anchors with shape (N, 7).\n",
    "        deltas (torch.Tensor): Encoded boxes with shape\n",
    "            (N, 7+n) [x, y, z, w, l, h, r, velo*].\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Decoded boxes.\n",
    "    \"\"\"\n",
    "    cas, cts = [], []\n",
    "    xa, ya, za, wa, la, ha, ra, *cas = torch.split(anchors, 1, dim=-1)\n",
    "    xt, yt, zt, wt, lt, ht, rt, *cts = torch.split(deltas, 1, dim=-1)\n",
    "\n",
    "    za = za + ha / 2\n",
    "    diagonal = torch.sqrt(la**2 + wa**2)\n",
    "    xg = xt * diagonal + xa\n",
    "    yg = yt * diagonal + ya\n",
    "    zg = zt * ha + za\n",
    "\n",
    "    lg = torch.exp(lt) * la\n",
    "    wg = torch.exp(wt) * wa\n",
    "    hg = torch.exp(ht) * ha\n",
    "    rg = rt + ra\n",
    "    zg = zg - hg / 2\n",
    "    cgs = [t + a for t, a in zip(cts, cas)]\n",
    "    return torch.cat([xg, yg, zg, wg, lg, hg, rg, *cgs], dim=-1)\n",
    "\n",
    "def limit_period(val, offset=0.0, period=np.pi):\n",
    "    return val - np.floor(val / period + 0.5) * period + offset\n",
    "\n",
    "def circle_nms_cpu(bboxes, scores, thresh):\n",
    "    order = scores.argsort()[::-1]\n",
    "    keep = []\n",
    "    suppressed = np.zeros(len(scores), dtype=bool)\n",
    "    for idx in order:\n",
    "        if suppressed[idx]:\n",
    "            continue\n",
    "        keep.append(idx)\n",
    "        # 抑制与当前框距离小于阈值的框\n",
    "        center = bboxes[idx, :2]\n",
    "        distances = np.linalg.norm(bboxes[:, :2] - center, axis=1)\n",
    "        suppressed = suppressed | (distances < thresh)\n",
    "    return keep\n",
    "\n",
    "import csv\n",
    "\n",
    "def save_box_pred_csv(boxes, file_name):\n",
    "    fieldnames = ['x', 'y', 'z', 'w', 'l', 'h', 'z_rotation', 'id', 'score']\n",
    "    try:\n",
    "        with open(file_name, 'w', newline='') as csvfile:\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames, delimiter=' ')\n",
    "            for box in boxes:\n",
    "                row = {\n",
    "                    'x': box['position']['x'],\n",
    "                    'y': box['position']['y'],\n",
    "                    'z': box['position']['z'],\n",
    "                    'w': box['size']['w'],\n",
    "                    'l': box['size']['l'],\n",
    "                    'h': box['size']['h'],\n",
    "                    'z_rotation': box['z_rotation'],\n",
    "                    'id': box['id'],\n",
    "                    'score': box['score'],\n",
    "                }\n",
    "                writer.writerow(row)\n",
    "        print(f\"Saved prediction in: {file_name}\")\n",
    "    except IOError:\n",
    "        print(\"Output file cannot be opened!\")\n",
    "\n",
    "\n",
    "#pytorch_model = init_model(os.path.join(model_root_path, \"fastbev_m0_r18_s256x704_v200x200x4_c192_d2_f1.py\"), device=DEVICE)\n",
    "#load_checkpoint(pytorch_model, backbone_model_path, map_location=DEVICE)\n",
    "\n",
    "\n",
    "\n",
    "#onnx_model = onnx.load(os.path.join(model_root_path, \"fastbev_post_trt.onnx\"))\n",
    "#trtModel_post = convert(onnx_model).to(DEVICE)\n",
    "#trtModel_post.eval()\n",
    "\n",
    "trtModel_post = torch.load(os.path.join(model_root_path, \"fastbev_post_trt.pth\"), weights_only=False).to(DEVICE)\n",
    "trtModel_post.eval()\n",
    "\n",
    "#model_int8 = edgeai_torchmodelopt.xmodelopt.quantization.v2.PTCFxModule(trtModel_post, backend='qnnpack', bias_calibration_factor=0.01, num_batch_norm_update_epochs=1, num_observer_update_epochs=2)\n",
    "\n",
    "\n",
    "# post_model_path = os.path.join(model_root_path, 'fastbev_post_trt.onnx')\n",
    "# post_session = ort.InferenceSession(post_model_path)\n",
    "\n",
    "# post_input_name = post_session.get_inputs()[0].name\n",
    "# post_output_names = [output.name for output in post_session.get_outputs()]\n",
    "\n",
    "anchors = Tensor()\n",
    "anchors = anchors.load(file_path=\"data/anchors.tensor\")\n",
    "anchors = torch.tensor(anchors.np(), dtype=torch.float32).to(DEVICE)\n",
    "\n",
    "accu_time = 0\n",
    "sample_results = []\n",
    "for sample_idx in range(num_samples):\n",
    "    time_start = time.time()\n",
    "    tensor_input = torch.tensor(sample_bev_features[sample_idx], dtype=torch.float32).to(DEVICE)\n",
    "    #print(tensor_input)\n",
    "    with torch.no_grad():\n",
    "        cls_scores,bbox_preds, dir_cls_pred = trtModel_post(tensor_input)\n",
    "        \"\"\"post_outputs = post_session.run(\n",
    "            post_output_names,\n",
    "            {post_input_name: sample_bev_features[sample_idx]}\n",
    "        ) \"\"\"\n",
    "        accu_time += time.time() - time_start\n",
    "\n",
    "        \"\"\"cls_scores = post_outputs[0]\n",
    "        bbox_preds = post_outputs[1]\n",
    "        dir_cls_pred = post_outputs[2] \"\"\"\n",
    "        \n",
    "        # 取每個樣本在所有類別的最大分數(沿 axis=1)\n",
    "        max_scores, _= cls_scores.max(dim=1) #np.max(cls_scores, axis=1)  # shape (N,)\n",
    "\n",
    "        # 取 top 1000 的索引值\n",
    "        _, topk_inds =  max_scores.topk(1000)#np.argsort(-max_scores)[:1000]\n",
    "        #print(topk_inds)\n",
    "\n",
    "        # 根據 topk_inds 篩選 anchors、bbox_preds、cls_scores、dir_cls_pred\n",
    "        anchorsTop = anchors[topk_inds, :]\n",
    "        bbox_pred_ = bbox_preds[topk_inds, :]\n",
    "\n",
    "        cls_scores = cls_scores[topk_inds, :]\n",
    "        dir_cls_scores = dir_cls_pred[topk_inds]\n",
    "        bbox_preds = decode(anchorsTop, bbox_pred_)\n",
    "\n",
    "    #torch to numpy\n",
    "    cls_scores = cls_scores.cpu().numpy()\n",
    "    bbox_preds = bbox_preds.cpu().numpy()\n",
    "    dir_cls_scores = dir_cls_scores.cpu().numpy()\n",
    "\n",
    "    param = {\n",
    "        'sorted_bboxes': True,\n",
    "        'confidence_threshold': 0.0,\n",
    "        'score_thr': 0.5,\n",
    "        'max_num': 500,\n",
    "        'dir_offset': 0.7854,  # 约等于 pi/4\n",
    "        'dir_limit_offset': 0.0,\n",
    "        'nms_radius_thr_list': [4.0, 12.0, 10.0, 10.0, 12.0, 0.85, 0.85, 0.175, 0.175, 1.0],\n",
    "        'nms_thr_list': [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.5, 0.5, 0.2],\n",
    "        'nms_rescale_factor': [1.0, 0.7, 0.55, 0.4, 0.7, 1.0, 1.0, 4.5, 9.0, 1.0],\n",
    "    }\n",
    "\n",
    "    num_boxes = bbox_preds.shape[0]\n",
    "    num_classes = cls_scores.shape[1]\n",
    "\n",
    "    # 准备用于 NMS 的边界框\n",
    "    mlvl_bboxes_for_nms = np.zeros((num_boxes, 5), dtype=np.float32)\n",
    "    mlvl_bboxes_for_nms[:, 0] = bbox_preds[:, 0]# x_center\n",
    "    mlvl_bboxes_for_nms[:, 1] = bbox_preds[:, 1]# y_center\n",
    "    mlvl_bboxes_for_nms[:, 2] = bbox_preds[:, 3]  # width\n",
    "    mlvl_bboxes_for_nms[:, 3] = bbox_preds[:, 4]  # length\n",
    "    mlvl_bboxes_for_nms[:, 4] = bbox_preds[:, 6]  # rotation angle (in radians)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for i in range(num_classes):\n",
    "        # 获取类别 i 的得分\n",
    "        scores = cls_scores[:, i]\n",
    "        mask = scores > param['score_thr']\n",
    "        if np.sum(mask) == 0:\n",
    "            continue  # 如果没有满足阈值的框，跳过\n",
    "\n",
    "        # 提取当前类别的数据\n",
    "        _scores_class = scores[mask]\n",
    "        _bboxes_for_nms_class = mlvl_bboxes_for_nms[mask]\n",
    "        _mlvl_bboxes_class = bbox_preds[mask]\n",
    "        _mlvl_dir_scores_class = dir_cls_scores[mask]\n",
    "\n",
    "        # 对边界框进行尺度调整\n",
    "        nms_rescale = param['nms_rescale_factor'][i]\n",
    "        _bboxes_for_nms_class = _bboxes_for_nms_class.copy()  # 避免修改原始数据\n",
    "        _bboxes_for_nms_class[:, 2] *= nms_rescale  # width\n",
    "        _bboxes_for_nms_class[:, 3] *= nms_rescale  # length\n",
    "\n",
    "        # 执行 NMS\n",
    "        if i == 9:\n",
    "            # 对于类别索引为 9，使用圆形 NMS\n",
    "            nms_thresh = param['nms_radius_thr_list'][i]\n",
    "            selected = circle_nms_cpu(_bboxes_for_nms_class, _scores_class, nms_thresh)\n",
    "        else:\n",
    "            # 其他类别使用旋转 NMS\n",
    "            nms_thresh = param['nms_thr_list'][i]\n",
    "            # 准备 boxes for nms_rotated (x_center, y_center, width, height, angle_in_degrees)\n",
    "            boxes_rotated = np.zeros((_bboxes_for_nms_class.shape[0], 5), dtype=np.float32)\n",
    "            boxes_rotated[:, 0] = _bboxes_for_nms_class[:, 0]  # x_center\n",
    "            boxes_rotated[:, 1] = _bboxes_for_nms_class[:, 1]  # y_center\n",
    "            boxes_rotated[:, 2] = _bboxes_for_nms_class[:, 2]  # width\n",
    "            boxes_rotated[:, 3] = _bboxes_for_nms_class[:, 3]  # length\n",
    "            boxes_rotated[:, 4] = -_bboxes_for_nms_class[:, 4]  # angle (in radians)\n",
    "\n",
    "            # 将数据转换为张量\n",
    "        #boxes_tensor = torch.from_numpy(boxes_rotated).float()\n",
    "            #scores_tensor = torch.from_numpy(_scores_class).float()\n",
    "\n",
    "            # 执行旋转 NMS\n",
    "            #from torchvision.ops import nms\n",
    "\n",
    "            width = boxes_rotated[:, 2]\n",
    "            height = boxes_rotated[:, 3]\n",
    "            angle = boxes_rotated[:, 4]\n",
    "\n",
    "            # Calculate the corners of the rotated boxes\n",
    "            #cos_angle = np.cos(angle)\n",
    "            #sin_angle = np.sin(angle)\n",
    "            half_width = width * 0.5\n",
    "            half_height = height * 0.5\n",
    "\n",
    "            x_center = boxes_rotated[:, 0]\n",
    "            y_center = boxes_rotated[:, 1]\n",
    "\n",
    "            x1 = x_center-half_width\n",
    "            y1 = y_center-half_height\n",
    "            x2 = x_center + half_width\n",
    "            y2 = y_center + half_height\n",
    "                #print(cos_angle[0])\n",
    "                #print(sin_angle[0])\n",
    "            #x1r = (x1 - x_center) * cos_angle + (y1 - y_center) * (sin_angle) + x_center\n",
    "            #y1r = -(x1 - x_center) * sin_angle + (y1 - y_center) * (cos_angle) + y_center\n",
    "            #x2r = (x2 - x_center) * cos_angle + (y2 - y_center) * (sin_angle) + x_center\n",
    "            #y2r = -(x2 - x_center) * sin_angle + (y2 - y_center) * (cos_angle) + y_center\n",
    "\n",
    "                \n",
    "            # Create axis-aligned boxes\n",
    "            xyxy =  np.stack([x1, y1, x2, y2, angle], axis=1)\n",
    "\n",
    "            selected = nms_cpu(xyxy, _scores_class, nms_thresh)\n",
    "\n",
    "        # 构建最终的检测结果\n",
    "        for idx in selected:\n",
    "            bbox = {}\n",
    "            # 位置\n",
    "            bbox['position'] = {\n",
    "                'x': _mlvl_bboxes_class[idx][0],\n",
    "                'y': _mlvl_bboxes_class[idx][1],\n",
    "                'z': _mlvl_bboxes_class[idx][2],\n",
    "            }\n",
    "            # 尺寸\n",
    "            bbox['size'] = {\n",
    "                'w': _mlvl_bboxes_class[idx][3],\n",
    "                'l': _mlvl_bboxes_class[idx][4],\n",
    "                'h': _mlvl_bboxes_class[idx][5],\n",
    "            }\n",
    "            # 计算旋转角度\n",
    "            dir_rot = limit_period(_mlvl_bboxes_class[idx][6] - param['dir_offset'],\n",
    "                                np.pi)\n",
    "            bbox['z_rotation'] = dir_rot + param['dir_offset'] + np.pi * _mlvl_dir_scores_class[idx]\n",
    "            # 速度\n",
    "            bbox['velocity'] = {\n",
    "                'vx': _mlvl_bboxes_class[idx][7],\n",
    "                'vy': _mlvl_bboxes_class[idx][8],\n",
    "            }\n",
    "            bbox['score'] = _scores_class[idx]\n",
    "            bbox['id'] = i  # 类别 ID\n",
    "            results.append(bbox)\n",
    "\n",
    "    # 根据需要排序并限制结果数量\n",
    "    if param['sorted_bboxes']:\n",
    "        # 根据得分从高到低排序\n",
    "        results = sorted(results, key=lambda x: x['score'], reverse=True)\n",
    "\n",
    "    # 限制返回的边界框数量\n",
    "    if len(results) > param['max_num']:\n",
    "        results = results[:param['max_num']]\n",
    "\n",
    "    #from pprint import pprint\n",
    "\n",
    "    print(\"Number of detected objects:\", len(results))\n",
    "    #pprint(results)\n",
    "    save_box_pred_csv(results, 'data/results/result_{:1d}.csv'.format(sample_idx))\n",
    "    sample_results.append(results)\n",
    "\n",
    "print(\"Inference time:\", accu_time/num_samples)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from pyquaternion.quaternion import Quaternion\n",
    "\n",
    "\n",
    "def check_point_in_img(points, height, width):\n",
    "    valid = np.logical_and(points[:, 0] >= 0, points[:, 1] >= 0)\n",
    "    valid = np.logical_and(valid, np.logical_and(points[:, 0] < width, points[:, 1] < height))\n",
    "    return valid\n",
    "\n",
    "\n",
    "def depth2color(depth):\n",
    "    gray = max(0, min((depth + 2.5) / 3.0, 1.0))\n",
    "    max_lumi = 200\n",
    "    colors = np.array([[max_lumi, 0, max_lumi], \n",
    "                       [max_lumi, 0, 0],\n",
    "                       [max_lumi, max_lumi, 0],\n",
    "                       [0, max_lumi, 0], \n",
    "                       [0, max_lumi, max_lumi], \n",
    "                       [0, 0, max_lumi]],\n",
    "        dtype=np.float32)\n",
    "    if gray == 1:\n",
    "        return tuple(colors[-1].tolist())\n",
    "    num_rank = len(colors) - 1\n",
    "    rank     = np.floor(gray * num_rank).astype(np.int32)\n",
    "    diff     = (gray - rank / num_rank) * num_rank\n",
    "    return tuple((colors[rank] + (colors[rank + 1] - colors[rank]) * diff).tolist())\n",
    "\n",
    "\n",
    "def lidar2img(points_lidar, camrera_info):\n",
    "    points_lidar_homogeneous  = np.concatenate([points_lidar, np.ones((points_lidar.shape[0], 1), dtype=points_lidar.dtype)], axis=1)\n",
    "    \n",
    "    lidar2camera              = camrera_info['lidar2img']['extrinsic']\n",
    "    lidar2camera              = np.array(lidar2camera, dtype=np.float32)\n",
    "    points_camera_homogeneous = points_lidar_homogeneous @ lidar2camera.T\n",
    "    points_camera             = points_camera_homogeneous[:, :3]\n",
    "    valid                     = np.ones((points_camera.shape[0]), dtype=bool)\n",
    "    valid                     = np.logical_and(points_camera[:, -1] > 0.5, valid)\n",
    "    points_camera             = points_camera / points_camera[:, 2:3]\n",
    "    camera2img                = np.array(camrera_info['lidar2img']['intrinsic'])\n",
    "    points_img                = points_camera @ camera2img.T\n",
    "    post_aug                  = np.eye(3, dtype=np.float32)\n",
    "    post_aug[:2, :2]          = np.array(camrera_info['post_rot'])[:2,:2]\n",
    "    post_aug[:2, 2]           = np.array(camrera_info['post_tran'])[:2]\n",
    "    points_img                = np.linalg.inv(post_aug) @ points_img.transpose(1,0)\n",
    "    points_img                = points_img.transpose(1,0)[:, :2]\n",
    "    return points_img, valid\n",
    "\n",
    "\n",
    "def get_lidar2global(lidar2ego_rotation, lidar2ego_translation, ego2global_rotation, ego2global_translation):\n",
    "    lidar2ego          = np.eye(4, dtype=np.float32)\n",
    "    lidar2ego[:3, :3]  = Quaternion(lidar2ego_rotation).rotation_matrix\n",
    "    lidar2ego[:3, 3]   = lidar2ego_translation\n",
    "    ego2global         = np.eye(4, dtype=np.float32)\n",
    "    ego2global[:3, :3] = Quaternion(ego2global_rotation).rotation_matrix\n",
    "    ego2global[:3, 3]  = ego2global_translation\n",
    "    return ego2global @ lidar2ego\n",
    "\n",
    "def create_lidar_box3d(tensor, box_dim=7, with_yaw=True, origin=(0.5, 0.5, 0)):\n",
    "    if isinstance(tensor, torch.Tensor):\n",
    "        device = tensor.device\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "    tensor = torch.as_tensor(tensor, dtype=torch.float32, device=device)\n",
    "    if tensor.numel() == 0:\n",
    "        # Use reshape, so we don't end up creating a new tensor that\n",
    "        # does not depend on the inputs (and consequently confuses jit)\n",
    "        tensor = tensor.reshape((0, box_dim)).to(\n",
    "            dtype=torch.float32, device=device)\n",
    "    assert tensor.dim() == 2 and tensor.size(-1) == box_dim, tensor.size()\n",
    "\n",
    "    if tensor.shape[-1] == 6:\n",
    "        # If the dimension of boxes is 6, we expand box_dim by padding\n",
    "        # 0 as a fake yaw and set with_yaw to False.\n",
    "        assert box_dim == 6\n",
    "        fake_rot = tensor.new_zeros(tensor.shape[0], 1)\n",
    "        tensor = torch.cat((tensor, fake_rot), dim=-1)\n",
    "        box_dim = box_dim + 1\n",
    "        with_yaw = False\n",
    "    else:\n",
    "        box_dim = box_dim\n",
    "        with_yaw = with_yaw\n",
    "    #tensor = tensor.clone()\n",
    "\n",
    "    if origin != (0.5, 0.5, 0):\n",
    "        dst = tensor.new_tensor((0.5, 0.5, 0))\n",
    "        src = tensor.new_tensor(origin)\n",
    "        tensor[:, :3] += tensor[:, 3:6] * (dst - src)\n",
    "    return tensor\n",
    "\n",
    "def rotation_3d_in_axis(points, angles, axis=0):\n",
    "    \"\"\"Rotate points by angles according to axis.\n",
    "\n",
    "    Args:\n",
    "        points (torch.Tensor): Points of shape (N, M, 3).\n",
    "        angles (torch.Tensor): Vector of angles in shape (N,)\n",
    "        axis (int, optional): The axis to be rotated. Defaults to 0.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: when the axis is not in range [0, 1, 2], it will \\\n",
    "            raise value error.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Rotated points in shape (N, M, 3)\n",
    "    \"\"\"\n",
    "    rot_sin = torch.sin(angles)\n",
    "    rot_cos = torch.cos(angles)\n",
    "    ones = torch.ones_like(rot_cos)\n",
    "    zeros = torch.zeros_like(rot_cos)\n",
    "    if axis == 1:\n",
    "        rot_mat_T = torch.stack([\n",
    "            torch.stack([rot_cos, zeros, -rot_sin]),\n",
    "            torch.stack([zeros, ones, zeros]),\n",
    "            torch.stack([rot_sin, zeros, rot_cos])\n",
    "        ])\n",
    "    elif axis == 2 or axis == -1:\n",
    "        rot_mat_T = torch.stack([\n",
    "            torch.stack([rot_cos, -rot_sin, zeros]),\n",
    "            torch.stack([rot_sin, rot_cos, zeros]),\n",
    "            torch.stack([zeros, zeros, ones])\n",
    "        ])\n",
    "    elif axis == 0:\n",
    "        rot_mat_T = torch.stack([\n",
    "            torch.stack([zeros, rot_cos, -rot_sin]),\n",
    "            torch.stack([zeros, rot_sin, rot_cos]),\n",
    "            torch.stack([ones, zeros, zeros])\n",
    "        ])\n",
    "    else:\n",
    "        raise ValueError(f'axis should in range [0, 1, 2], got {axis}')\n",
    "\n",
    "    return torch.einsum('aij,jka->aik', (points, rot_mat_T))\n",
    "\n",
    "def corners(dims, tensor):\n",
    "    \"\"\"torch.Tensor: Coordinates of corners of all the boxes\n",
    "    in shape (N, 8, 3).\n",
    "\n",
    "    Convert the boxes to corners in clockwise order, in form of\n",
    "    ``(x0y0z0, x0y0z1, x0y1z1, x0y1z0, x1y0z0, x1y0z1, x1y1z1, x1y1z0)``\n",
    "\n",
    "    .. code-block:: none\n",
    "\n",
    "                                           up z\n",
    "                            front x           ^\n",
    "                                 /            |\n",
    "                                /             |\n",
    "                  (x1, y0, z1) + -----------  + (x1, y1, z1)\n",
    "                              /|            / |\n",
    "                             / |           /  |\n",
    "               (x0, y0, z1) + ----------- +   + (x1, y1, z0)\n",
    "                            |  /      .   |  /\n",
    "                            | / oriign    | /\n",
    "            left y<-------- + ----------- + (x0, y1, z0)\n",
    "                (x0, y0, z0)\n",
    "    \"\"\"\n",
    "    # TODO: rotation_3d_in_axis function do not support\n",
    "    #  empty tensor currently.\n",
    "    corners_norm = torch.from_numpy(\n",
    "        np.stack(np.unravel_index(np.arange(8), [2] * 3), axis=1)).to(\n",
    "            device=dims.device, dtype=dims.dtype)\n",
    "\n",
    "    corners_norm = corners_norm[[0, 1, 3, 2, 4, 5, 7, 6]]\n",
    "    # use relative origin [0.5, 0.5, 0]\n",
    "    corners_norm = corners_norm - dims.new_tensor([0.5, 0.5, 0])\n",
    "    corners = dims.view([-1, 1, 3]) * corners_norm.reshape([1, 8, 3])\n",
    "\n",
    "    # rotate around z axis\n",
    "    corners = rotation_3d_in_axis(corners, tensor[:, 6], axis=2)\n",
    "    corners += tensor[:, :3].view(-1, 1, 3)\n",
    "    return corners\n",
    "\n",
    "def convert_predictions_to_arrays(results):\n",
    "    import numpy as np\n",
    "\n",
    "    bboxes = []\n",
    "    scores = []\n",
    "    cls_arr = []\n",
    "\n",
    "    for bbox in results:\n",
    "        # 提取位置和尺寸信息\n",
    "        x = bbox['position']['x']\n",
    "        y = bbox['position']['y']\n",
    "        z = bbox['position']['z']\n",
    "        w = bbox['size']['w']\n",
    "        l = bbox['size']['l']\n",
    "        h = bbox['size']['h']\n",
    "        # 提取旋转角度\n",
    "        yaw = bbox['z_rotation']\n",
    "        # 构建边界框数组，格式为 [x, y, z, w, l, h, yaw]\n",
    "        bboxes.append([x, y, z, w, l, h, yaw])\n",
    "        # 提取得分\n",
    "        scores.append(bbox['score'])\n",
    "        # 提取类别 ID\n",
    "        cls_arr.append(bbox['id'])\n",
    "\n",
    "    # 将列表转换为 NumPy 数组\n",
    "    bboxes = np.array(bboxes, dtype=np.float32)\n",
    "    scores = np.array(scores, dtype=np.float32)\n",
    "    cls_arr = np.array(cls_arr, dtype=np.int32)\n",
    "\n",
    "    return bboxes, scores, cls_arr\n",
    "\n",
    "def visualize(data_root, predictions,vis_path, sample_idx):\n",
    "    info_dict = None\n",
    "    with open(os.path.join(data_root, \"sensor.json\"), 'r') as f:\n",
    "        info_dict = json.load(f)\n",
    "    cam_info_dict = info_dict['cams']\n",
    "\n",
    "    #bboxes, scores, cls_arr = read_txt_to_array(pred_path)\n",
    "    bboxes, scores, cls_arr = convert_predictions_to_arrays(predictions)\n",
    "\n",
    "    # 定义绘制BEV视角下框的索引\n",
    "    draw_boxes_indexes_bev      = [(0, 1), (1, 2), (2, 3), (3, 0)]\n",
    "    draw_boxes_indexes_img_view = [(0, 1), (1, 2), (2, 3), (3, 0), (4, 5), (5, 6), \n",
    "                                   (6, 7), (7, 4), (0, 4), (1, 5), (2, 6), (3, 7)]\n",
    "    canva_size   = 1000\n",
    "    show_range   = 50\n",
    "    scale_factor = 4\n",
    "    color_map    = {0: (255, 255, 0), 1: (0, 255, 255)}\n",
    "\n",
    "    # 定义相机视角列表\n",
    "    print('start visualizing results')\n",
    "    pred_boxes        = np.array(bboxes, dtype=np.float32)\n",
    "    #corners_lidar     = LB(pred_boxes, origin=(0.5, 0.5, 0)).corners.numpy().reshape(-1, 3)\n",
    "    box3d = create_lidar_box3d(pred_boxes, origin=(0.5, 0.5, 0))\n",
    "    box3d_dims = box3d[:, 3:6]\n",
    "    corners_lidar = corners(box3d_dims, box3d).numpy().reshape(-1, 3)\n",
    "\n",
    "    #print(corners_lidar)\n",
    "    #dd = LB(pred_boxes, origin=(0.5, 0.5, 0)).corners.numpy().reshape(-1, 3)\n",
    "    #print(dd)\n",
    "\n",
    "    pred_flag = np.ones((corners_lidar.shape[0] // 8, ), dtype=np.bool)\n",
    "    scores    = np.array(scores, dtype=np.float32)\n",
    "\n",
    "    # 构建预测框的标志数组\n",
    "    sort_ids  = np.argsort(scores)\n",
    "\n",
    "    # 对相机视角进行可视化\n",
    "    imgs = []\n",
    "    views = ['CAM_FRONT_LEFT', 'CAM_FRONT', 'CAM_FRONT_RIGHT', 'CAM_BACK_LEFT', 'CAM_BACK', 'CAM_BACK_RIGHT']\n",
    "    img_paths = []\n",
    "    img_paths.append(f'data/samples/front_left/front_left_{sample_idx+1}.jpg')\n",
    "    img_paths.append(f'data/samples/front/front_{sample_idx+1}.jpg')\n",
    "    img_paths.append(f'data/samples/front_right/front_right_{sample_idx+1}.jpg')\n",
    "    img_paths.append(f'data/samples/back_left/back_left_{sample_idx+1}.jpg')\n",
    "    img_paths.append(f'data/samples/back/back_{sample_idx+1}.jpg')\n",
    "    img_paths.append(f'data/samples/back_right/back_right_{sample_idx+1}.jpg')\n",
    "    idx = 0\n",
    "    for view in views:\n",
    "        img = cv2.imread(img_paths[idx])\n",
    "        idx += 1\n",
    "        # 将雷达坐标转换为图像坐标并绘制目标框\n",
    "        corners_img, valid = lidar2img(corners_lidar, cam_info_dict[view])\n",
    "        valid = valid.reshape(-1, 8)\n",
    "        corners_img = corners_img.reshape(-1, 8, 2).astype(np.int32)\n",
    "        for aid in range(valid.shape[0]):\n",
    "            for index in draw_boxes_indexes_img_view:\n",
    "                if valid[aid, index[0]] and valid[aid, index[1]]:\n",
    "                    cv2.line(img, corners_img[aid, index[0]], corners_img[aid, index[1]],\n",
    "                            color=color_map[int(pred_flag[aid])], thickness=scale_factor)\n",
    "        imgs.append(img)\n",
    "\n",
    "    # 构建BEV视图的画布\n",
    "    canvas = np.zeros((int(canva_size), int(canva_size), 3), dtype=np.uint8)\n",
    "\n",
    "\n",
    "    ## 绘制中心点和距离\n",
    "    center_ego = (0, 0)\n",
    "    center_canvas = int((center_ego[0] + show_range) / show_range / 2.0 * canva_size)\n",
    "    cv2.circle(canvas, center=(center_canvas, center_canvas), radius=1, color=(255, 255, 255), thickness=0)\n",
    "    dis = 10\n",
    "    for r in range(dis, 100, dis):\n",
    "        r_canvas = int(r / show_range / 2.0 * canva_size)\n",
    "        cv2.circle(canvas, center=(center_canvas, center_canvas), radius=r_canvas, color=depth2color(r), thickness=0)\n",
    "        \n",
    "    \n",
    "    # 绘制BEV视角下的预测框\n",
    "    corners_lidar          = corners_lidar.reshape(-1, 8, 3)\n",
    "    corners_lidar[:, :, 1] = -corners_lidar[:, :, 1]\n",
    "    bottom_corners_bev     = corners_lidar[:, [0, 3, 7, 4], :2]\n",
    "    bottom_corners_bev     = (bottom_corners_bev + show_range) / show_range / 2.0 * canva_size\n",
    "    bottom_corners_bev     = np.round(bottom_corners_bev).astype(np.int32)\n",
    "    center_bev             = corners_lidar[:, [0, 3, 7, 4], :2].mean(axis=1)\n",
    "    head_bev               = corners_lidar[:, [0, 4], :2].mean(axis=1)\n",
    "    canter_canvas          = (center_bev + show_range) / show_range / 2.0 * canva_size\n",
    "    center_canvas          = canter_canvas.astype(np.int32)\n",
    "    head_canvas            = (head_bev + show_range) / show_range / 2.0 * canva_size\n",
    "    head_canvas            = head_canvas.astype(np.int32)\n",
    "\n",
    "    # 在BEV视角下绘制预测框\n",
    "    for rid in sort_ids:\n",
    "        score = scores[rid]\n",
    "        if score < 0.2 and pred_flag[rid]:\n",
    "            continue\n",
    "        score = min(score * 2.0, 1.0) if pred_flag[rid] else 1.0\n",
    "        color = color_map[int(pred_flag[rid])]\n",
    "        for index in draw_boxes_indexes_bev:\n",
    "            cv2.line(canvas, bottom_corners_bev[rid, index[0]], bottom_corners_bev[rid, index[1]],\n",
    "                    [color[0] * score, color[1] * score, color[2] * score], thickness=1)\n",
    "        cv2.line(canvas, center_canvas[rid], head_canvas[rid], [color[0] * score, color[1] * score, color[2] * score], 1, lineType=8)\n",
    "\n",
    "    # 融合图像视角和BEV视角的结果\n",
    "    img = np.zeros((900 * 2 + canva_size * scale_factor, 1600 * 3, 3), dtype=np.uint8)\n",
    "    img[:900, :, :] = np.concatenate(imgs[:3], axis=1)\n",
    "    img_back = np.concatenate([imgs[3][:, ::-1, :], imgs[4][:, ::-1, :], imgs[5][:, ::-1, :]], axis=1)\n",
    "    img[900 + canva_size * scale_factor:, :, :] = img_back\n",
    "    img = cv2.resize(img, (int(1600 / scale_factor * 3), int(900 / scale_factor * 2 + canva_size)))\n",
    "    w_begin = int((1600 * 3 / scale_factor - canva_size) // 2)\n",
    "    img[int(900 / scale_factor):int(900 / scale_factor) + canva_size, w_begin:w_begin + canva_size, :] = canvas\n",
    "\n",
    "    # 保存可视化结果\n",
    "    \n",
    "    #cv2.imwrite(vis_path, img)\n",
    "    plt.close()\n",
    "    plt.figure(figsize=(25, 12))\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(img_rgb)\n",
    "    plt.axis('off')  # Hide axis ticks and labels\n",
    "    #plt.show()\n",
    "    plt.savefig(vis_path)  \n",
    "    print(f'Saved visual result to {vis_path}')\n",
    "\n",
    "\n",
    "\"\"\" def convert_tensors_to_lists(data):\n",
    "    if isinstance(data, dict):\n",
    "        return {key: convert_tensors_to_lists(value) for key, value in data.items()}\n",
    "    elif isinstance(data, list):\n",
    "        return [convert_tensors_to_lists(element) for element in data]\n",
    "    elif isinstance(data, torch.Tensor):\n",
    "        return data.tolist()\n",
    "    elif isinstance(data, np.ndarray):\n",
    "        return data.tolist()\n",
    "    else:\n",
    "        return data\n",
    "\n",
    "def save_info_dict_to_json(info_dict, output_file):\n",
    "    # 首先将不可序列化的数据类型转换为可序列化的类型\n",
    "    serializable_info_dict = convert_tensors_to_lists(info_dict)\n",
    "\n",
    "    # 保存为 JSON 文件\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(serializable_info_dict, f, indent=4)\n",
    "\n",
    "    print(f\"Saved info_dict to {output_file}\") \"\"\"\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    data_root  = 'data'\n",
    "    pred_path  = 'result.txt'\n",
    "    vis_path   = os.path.join(data_root, \"sample0_vis.png\")\n",
    "\n",
    "    for sample_idx in range(num_samples):\n",
    "        visualize(data_root, sample_results[sample_idx], f'data/results/result_{sample_idx}.png', sample_idx)\n",
    "    #save_info_dict_to_json(read_data_file('example-data'), 'example-data.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from pyquaternion.quaternion import Quaternion\n",
    "\n",
    "\n",
    "def check_point_in_img(points, height, width):\n",
    "    valid = np.logical_and(points[:, 0] >= 0, points[:, 1] >= 0)\n",
    "    valid = np.logical_and(valid, np.logical_and(points[:, 0] < width, points[:, 1] < height))\n",
    "    return valid\n",
    "\n",
    "\n",
    "def depth2color(depth):\n",
    "    gray = max(0, min((depth + 2.5) / 3.0, 1.0))\n",
    "    max_lumi = 200\n",
    "    colors = np.array([[max_lumi, 0, max_lumi], \n",
    "                       [max_lumi, 0, 0],\n",
    "                       [max_lumi, max_lumi, 0],\n",
    "                       [0, max_lumi, 0], \n",
    "                       [0, max_lumi, max_lumi], \n",
    "                       [0, 0, max_lumi]],\n",
    "        dtype=np.float32)\n",
    "    if gray == 1:\n",
    "        return tuple(colors[-1].tolist())\n",
    "    num_rank = len(colors) - 1\n",
    "    rank     = np.floor(gray * num_rank).astype(np.int32)\n",
    "    diff     = (gray - rank / num_rank) * num_rank\n",
    "    return tuple((colors[rank] + (colors[rank + 1] - colors[rank]) * diff).tolist())\n",
    "\n",
    "\n",
    "def lidar2img(points_lidar, camrera_info):\n",
    "    points_lidar_homogeneous  = np.concatenate([points_lidar, np.ones((points_lidar.shape[0], 1), dtype=points_lidar.dtype)], axis=1)\n",
    "    \n",
    "    lidar2camera              = camrera_info['lidar2img']['extrinsic']\n",
    "    lidar2camera              = np.array(lidar2camera, dtype=np.float32)\n",
    "    points_camera_homogeneous = points_lidar_homogeneous @ lidar2camera.T\n",
    "    points_camera             = points_camera_homogeneous[:, :3]\n",
    "    valid                     = np.ones((points_camera.shape[0]), dtype=bool)\n",
    "    valid                     = np.logical_and(points_camera[:, -1] > 0.5, valid)\n",
    "    points_camera             = points_camera / points_camera[:, 2:3]\n",
    "    camera2img                = np.array(camrera_info['lidar2img']['intrinsic'])\n",
    "    points_img                = points_camera @ camera2img.T\n",
    "    post_aug                  = np.eye(3, dtype=np.float32)\n",
    "    post_aug[:2, :2]          = np.array(camrera_info['post_rot'])[:2,:2]\n",
    "    post_aug[:2, 2]           = np.array(camrera_info['post_tran'])[:2]\n",
    "    points_img                = np.linalg.inv(post_aug) @ points_img.transpose(1,0)\n",
    "    points_img                = points_img.transpose(1,0)[:, :2]\n",
    "    return points_img, valid\n",
    "\n",
    "\n",
    "def get_lidar2global(lidar2ego_rotation, lidar2ego_translation, ego2global_rotation, ego2global_translation):\n",
    "    lidar2ego          = np.eye(4, dtype=np.float32)\n",
    "    lidar2ego[:3, :3]  = Quaternion(lidar2ego_rotation).rotation_matrix\n",
    "    lidar2ego[:3, 3]   = lidar2ego_translation\n",
    "    ego2global         = np.eye(4, dtype=np.float32)\n",
    "    ego2global[:3, :3] = Quaternion(ego2global_rotation).rotation_matrix\n",
    "    ego2global[:3, 3]  = ego2global_translation\n",
    "    return ego2global @ lidar2ego\n",
    "\n",
    "def create_lidar_box3d(tensor, box_dim=7, with_yaw=True, origin=(0.5, 0.5, 0)):\n",
    "    if isinstance(tensor, torch.Tensor):\n",
    "        device = tensor.device\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "    tensor = torch.as_tensor(tensor, dtype=torch.float32, device=device)\n",
    "    if tensor.numel() == 0:\n",
    "        # Use reshape, so we don't end up creating a new tensor that\n",
    "        # does not depend on the inputs (and consequently confuses jit)\n",
    "        tensor = tensor.reshape((0, box_dim)).to(\n",
    "            dtype=torch.float32, device=device)\n",
    "    assert tensor.dim() == 2 and tensor.size(-1) == box_dim, tensor.size()\n",
    "\n",
    "    if tensor.shape[-1] == 6:\n",
    "        # If the dimension of boxes is 6, we expand box_dim by padding\n",
    "        # 0 as a fake yaw and set with_yaw to False.\n",
    "        assert box_dim == 6\n",
    "        fake_rot = tensor.new_zeros(tensor.shape[0], 1)\n",
    "        tensor = torch.cat((tensor, fake_rot), dim=-1)\n",
    "        box_dim = box_dim + 1\n",
    "        with_yaw = False\n",
    "    else:\n",
    "        box_dim = box_dim\n",
    "        with_yaw = with_yaw\n",
    "    #tensor = tensor.clone()\n",
    "\n",
    "    if origin != (0.5, 0.5, 0):\n",
    "        dst = tensor.new_tensor((0.5, 0.5, 0))\n",
    "        src = tensor.new_tensor(origin)\n",
    "        tensor[:, :3] += tensor[:, 3:6] * (dst - src)\n",
    "    return tensor\n",
    "\n",
    "def rotation_3d_in_axis(points, angles, axis=0):\n",
    "    \"\"\"Rotate points by angles according to axis.\n",
    "\n",
    "    Args:\n",
    "        points (torch.Tensor): Points of shape (N, M, 3).\n",
    "        angles (torch.Tensor): Vector of angles in shape (N,)\n",
    "        axis (int, optional): The axis to be rotated. Defaults to 0.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: when the axis is not in range [0, 1, 2], it will \\\n",
    "            raise value error.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Rotated points in shape (N, M, 3)\n",
    "    \"\"\"\n",
    "    rot_sin = torch.sin(angles)\n",
    "    rot_cos = torch.cos(angles)\n",
    "    ones = torch.ones_like(rot_cos)\n",
    "    zeros = torch.zeros_like(rot_cos)\n",
    "    if axis == 1:\n",
    "        rot_mat_T = torch.stack([\n",
    "            torch.stack([rot_cos, zeros, -rot_sin]),\n",
    "            torch.stack([zeros, ones, zeros]),\n",
    "            torch.stack([rot_sin, zeros, rot_cos])\n",
    "        ])\n",
    "    elif axis == 2 or axis == -1:\n",
    "        rot_mat_T = torch.stack([\n",
    "            torch.stack([rot_cos, -rot_sin, zeros]),\n",
    "            torch.stack([rot_sin, rot_cos, zeros]),\n",
    "            torch.stack([zeros, zeros, ones])\n",
    "        ])\n",
    "    elif axis == 0:\n",
    "        rot_mat_T = torch.stack([\n",
    "            torch.stack([zeros, rot_cos, -rot_sin]),\n",
    "            torch.stack([zeros, rot_sin, rot_cos]),\n",
    "            torch.stack([ones, zeros, zeros])\n",
    "        ])\n",
    "    else:\n",
    "        raise ValueError(f'axis should in range [0, 1, 2], got {axis}')\n",
    "\n",
    "    return torch.einsum('aij,jka->aik', (points, rot_mat_T))\n",
    "\n",
    "def corners(dims, tensor):\n",
    "    \"\"\"torch.Tensor: Coordinates of corners of all the boxes\n",
    "    in shape (N, 8, 3).\n",
    "\n",
    "    Convert the boxes to corners in clockwise order, in form of\n",
    "    ``(x0y0z0, x0y0z1, x0y1z1, x0y1z0, x1y0z0, x1y0z1, x1y1z1, x1y1z0)``\n",
    "\n",
    "    .. code-block:: none\n",
    "\n",
    "                                           up z\n",
    "                            front x           ^\n",
    "                                 /            |\n",
    "                                /             |\n",
    "                  (x1, y0, z1) + -----------  + (x1, y1, z1)\n",
    "                              /|            / |\n",
    "                             / |           /  |\n",
    "               (x0, y0, z1) + ----------- +   + (x1, y1, z0)\n",
    "                            |  /      .   |  /\n",
    "                            | / oriign    | /\n",
    "            left y<-------- + ----------- + (x0, y1, z0)\n",
    "                (x0, y0, z0)\n",
    "    \"\"\"\n",
    "    # TODO: rotation_3d_in_axis function do not support\n",
    "    #  empty tensor currently.\n",
    "    corners_norm = torch.from_numpy(\n",
    "        np.stack(np.unravel_index(np.arange(8), [2] * 3), axis=1)).to(\n",
    "            device=dims.device, dtype=dims.dtype)\n",
    "\n",
    "    corners_norm = corners_norm[[0, 1, 3, 2, 4, 5, 7, 6]]\n",
    "    # use relative origin [0.5, 0.5, 0]\n",
    "    corners_norm = corners_norm - dims.new_tensor([0.5, 0.5, 0])\n",
    "    corners = dims.view([-1, 1, 3]) * corners_norm.reshape([1, 8, 3])\n",
    "\n",
    "    # rotate around z axis\n",
    "    corners = rotation_3d_in_axis(corners, tensor[:, 6], axis=2)\n",
    "    corners += tensor[:, :3].view(-1, 1, 3)\n",
    "    return corners\n",
    "\n",
    "def convert_predictions_to_arrays(results):\n",
    "    import numpy as np\n",
    "\n",
    "    bboxes = []\n",
    "    scores = []\n",
    "    cls_arr = []\n",
    "\n",
    "    for bbox in results:\n",
    "        # 提取位置和尺寸信息\n",
    "        x = bbox['position']['x']\n",
    "        y = bbox['position']['y']\n",
    "        z = bbox['position']['z']\n",
    "        w = bbox['size']['w']\n",
    "        l = bbox['size']['l']\n",
    "        h = bbox['size']['h']\n",
    "        # 提取旋转角度\n",
    "        yaw = bbox['z_rotation']\n",
    "        # 构建边界框数组，格式为 [x, y, z, w, l, h, yaw]\n",
    "        bboxes.append([x, y, z, w, l, h, yaw])\n",
    "        # 提取得分\n",
    "        scores.append(bbox['score'])\n",
    "        # 提取类别 ID\n",
    "        cls_arr.append(bbox['id'])\n",
    "\n",
    "    # 将列表转换为 NumPy 数组\n",
    "    bboxes = np.array(bboxes, dtype=np.float32)\n",
    "    scores = np.array(scores, dtype=np.float32)\n",
    "    cls_arr = np.array(cls_arr, dtype=np.int32)\n",
    "\n",
    "    return bboxes, scores, cls_arr\n",
    "\n",
    "def visualize(data_root, predictions,vis_path, sample_idx):\n",
    "    info_dict = None\n",
    "    with open(os.path.join(data_root, \"sensor.json\"), 'r') as f:\n",
    "        info_dict = json.load(f)\n",
    "    cam_info_dict = info_dict['cams']\n",
    "\n",
    "    #bboxes, scores, cls_arr = read_txt_to_array(pred_path)\n",
    "    bboxes, scores, cls_arr = convert_predictions_to_arrays(predictions)\n",
    "\n",
    "    # 定义绘制BEV视角下框的索引\n",
    "    draw_boxes_indexes_bev      = [(0, 1), (1, 2), (2, 3), (3, 0)]\n",
    "    draw_boxes_indexes_img_view = [(0, 1), (1, 2), (2, 3), (3, 0), (4, 5), (5, 6), \n",
    "                                   (6, 7), (7, 4), (0, 4), (1, 5), (2, 6), (3, 7)]\n",
    "    canva_size   = 1000\n",
    "    show_range   = 50\n",
    "    scale_factor = 4\n",
    "    color_map    = {0: (255, 255, 0), 1: (0, 255, 255)}\n",
    "\n",
    "    # 定义相机视角列表\n",
    "    print('start visualizing results')\n",
    "    pred_boxes        = np.array(bboxes, dtype=np.float32)\n",
    "    #corners_lidar     = LB(pred_boxes, origin=(0.5, 0.5, 0)).corners.numpy().reshape(-1, 3)\n",
    "    box3d = create_lidar_box3d(pred_boxes, origin=(0.5, 0.5, 0))\n",
    "    box3d_dims = box3d[:, 3:6]\n",
    "    corners_lidar = corners(box3d_dims, box3d).numpy().reshape(-1, 3)\n",
    "\n",
    "    #print(corners_lidar)\n",
    "    #dd = LB(pred_boxes, origin=(0.5, 0.5, 0)).corners.numpy().reshape(-1, 3)\n",
    "    #print(dd)\n",
    "\n",
    "    pred_flag = np.ones((corners_lidar.shape[0] // 8, ), dtype=np.bool)\n",
    "    scores    = np.array(scores, dtype=np.float32)\n",
    "\n",
    "    # 构建预测框的标志数组\n",
    "    sort_ids  = np.argsort(scores)\n",
    "\n",
    "    # 对相机视角进行可视化\n",
    "    imgs = []\n",
    "    views = ['CAM_FRONT_LEFT', 'CAM_FRONT', 'CAM_FRONT_RIGHT', 'CAM_BACK_LEFT', 'CAM_BACK', 'CAM_BACK_RIGHT']\n",
    "    img_paths = []\n",
    "    img_paths.append(f'data/samples/front_left/front_left_{sample_idx+1}.jpg')\n",
    "    img_paths.append(f'data/samples/front/front_{sample_idx+1}.jpg')\n",
    "    img_paths.append(f'data/samples/front_right/front_right_{sample_idx+1}.jpg')\n",
    "    img_paths.append(f'data/samples/back_left/back_left_{sample_idx+1}.jpg')\n",
    "    img_paths.append(f'data/samples/back/back_{sample_idx+1}.jpg')\n",
    "    img_paths.append(f'data/samples/back_right/back_right_{sample_idx+1}.jpg')\n",
    "    idx = 0\n",
    "    for view in views:\n",
    "        img = cv2.imread(img_paths[idx])\n",
    "        idx += 1\n",
    "        # 将雷达坐标转换为图像坐标并绘制目标框\n",
    "        corners_img, valid = lidar2img(corners_lidar, cam_info_dict[view])\n",
    "        valid = valid.reshape(-1, 8)\n",
    "        corners_img = corners_img.reshape(-1, 8, 2).astype(np.int32)\n",
    "        for aid in range(valid.shape[0]):\n",
    "            for index in draw_boxes_indexes_img_view:\n",
    "                if valid[aid, index[0]] and valid[aid, index[1]]:\n",
    "                    cv2.line(img, corners_img[aid, index[0]], corners_img[aid, index[1]],\n",
    "                            color=color_map[int(pred_flag[aid])], thickness=scale_factor)\n",
    "        imgs.append(img)\n",
    "\n",
    "    # 构建BEV视图的画布\n",
    "    canvas = np.zeros((int(canva_size), int(canva_size), 3), dtype=np.uint8)\n",
    "\n",
    "\n",
    "    ## 绘制中心点和距离\n",
    "    center_ego = (0, 0)\n",
    "    center_canvas = int((center_ego[0] + show_range) / show_range / 2.0 * canva_size)\n",
    "    cv2.circle(canvas, center=(center_canvas, center_canvas), radius=1, color=(255, 255, 255), thickness=0)\n",
    "    dis = 10\n",
    "    for r in range(dis, 100, dis):\n",
    "        r_canvas = int(r / show_range / 2.0 * canva_size)\n",
    "        cv2.circle(canvas, center=(center_canvas, center_canvas), radius=r_canvas, color=depth2color(r), thickness=0)\n",
    "        \n",
    "    \n",
    "    # 绘制BEV视角下的预测框\n",
    "    corners_lidar          = corners_lidar.reshape(-1, 8, 3)\n",
    "    corners_lidar[:, :, 1] = -corners_lidar[:, :, 1]\n",
    "    bottom_corners_bev     = corners_lidar[:, [0, 3, 7, 4], :2]\n",
    "    bottom_corners_bev     = (bottom_corners_bev + show_range) / show_range / 2.0 * canva_size\n",
    "    bottom_corners_bev     = np.round(bottom_corners_bev).astype(np.int32)\n",
    "    center_bev             = corners_lidar[:, [0, 3, 7, 4], :2].mean(axis=1)\n",
    "    head_bev               = corners_lidar[:, [0, 4], :2].mean(axis=1)\n",
    "    canter_canvas          = (center_bev + show_range) / show_range / 2.0 * canva_size\n",
    "    center_canvas          = canter_canvas.astype(np.int32)\n",
    "    head_canvas            = (head_bev + show_range) / show_range / 2.0 * canva_size\n",
    "    head_canvas            = head_canvas.astype(np.int32)\n",
    "\n",
    "    # 在BEV视角下绘制预测框\n",
    "    for rid in sort_ids:\n",
    "        score = scores[rid]\n",
    "        if score < 0.2 and pred_flag[rid]:\n",
    "            continue\n",
    "        score = min(score * 2.0, 1.0) if pred_flag[rid] else 1.0\n",
    "        color = color_map[int(pred_flag[rid])]\n",
    "        for index in draw_boxes_indexes_bev:\n",
    "            cv2.line(canvas, bottom_corners_bev[rid, index[0]], bottom_corners_bev[rid, index[1]],\n",
    "                    [color[0] * score, color[1] * score, color[2] * score], thickness=1)\n",
    "        cv2.line(canvas, center_canvas[rid], head_canvas[rid], [color[0] * score, color[1] * score, color[2] * score], 1, lineType=8)\n",
    "\n",
    "    # 融合图像视角和BEV视角的结果\n",
    "    img = np.zeros((900 * 2 + canva_size * scale_factor, 1600 * 3, 3), dtype=np.uint8)\n",
    "    img[:900, :, :] = np.concatenate(imgs[:3], axis=1)\n",
    "    img_back = np.concatenate([imgs[3][:, ::-1, :], imgs[4][:, ::-1, :], imgs[5][:, ::-1, :]], axis=1)\n",
    "    img[900 + canva_size * scale_factor:, :, :] = img_back\n",
    "    img = cv2.resize(img, (int(1600 / scale_factor * 3), int(900 / scale_factor * 2 + canva_size)))\n",
    "    w_begin = int((1600 * 3 / scale_factor - canva_size) // 2)\n",
    "    img[int(900 / scale_factor):int(900 / scale_factor) + canva_size, w_begin:w_begin + canva_size, :] = canvas\n",
    "\n",
    "    # 保存可视化结果\n",
    "    \n",
    "    #cv2.imwrite(vis_path, img)\n",
    "    plt.close()\n",
    "    plt.figure(figsize=(25, 12))\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(img_rgb)\n",
    "    plt.axis('off')  # Hide axis ticks and labels\n",
    "    #plt.show()\n",
    "    plt.savefig(vis_path)  \n",
    "    print(f'Saved visual result to {vis_path}')\n",
    "\n",
    "\n",
    "\"\"\" def convert_tensors_to_lists(data):\n",
    "    if isinstance(data, dict):\n",
    "        return {key: convert_tensors_to_lists(value) for key, value in data.items()}\n",
    "    elif isinstance(data, list):\n",
    "        return [convert_tensors_to_lists(element) for element in data]\n",
    "    elif isinstance(data, torch.Tensor):\n",
    "        return data.tolist()\n",
    "    elif isinstance(data, np.ndarray):\n",
    "        return data.tolist()\n",
    "    else:\n",
    "        return data\n",
    "\n",
    "def save_info_dict_to_json(info_dict, output_file):\n",
    "    # 首先将不可序列化的数据类型转换为可序列化的类型\n",
    "    serializable_info_dict = convert_tensors_to_lists(info_dict)\n",
    "\n",
    "    # 保存为 JSON 文件\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(serializable_info_dict, f, indent=4)\n",
    "\n",
    "    print(f\"Saved info_dict to {output_file}\") \"\"\"\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    data_root  = 'data'\n",
    "    pred_path  = 'result.txt'\n",
    "    vis_path   = os.path.join(data_root, \"sample0_vis.png\")\n",
    "\n",
    "    for sample_idx in range(num_samples):\n",
    "        visualize(data_root, sample_results[sample_idx], f'data/results/result_{sample_idx}.png', sample_idx)\n",
    "    #save_info_dict_to_json(read_data_file('example-data'), 'example-data.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tidl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
